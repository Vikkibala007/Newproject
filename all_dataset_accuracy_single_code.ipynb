{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb6St3W+9YtdmmMmalfqFg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vikkibala007/Newproject/blob/main/all_dataset_accuracy_single_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_EzkW87dQLj",
        "outputId": "1aadf661-59d8-435f-b6ea-e44a9de0afab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: reprocessed.hungarian.csv\n",
            "Results for file: reprocessed.hungarian.csv\n",
            "Model: Logistic Regression\n",
            "Accuracy: 0.6893617021276596\n",
            "F1 Score: 0.6473931509435616\n",
            "Precision: 0.6293161072455022\n",
            "Recall: 0.6893617021276596\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "\n",
            "Model: Naive Bayes\n",
            "Accuracy: 0.676595744680851\n",
            "F1 Score: 0.6541393376465879\n",
            "Precision: 0.6530325519452862\n",
            "Recall: 0.676595744680851\n",
            "\n",
            "Model: Neural Network\n",
            "Accuracy: 0.8680851063829788\n",
            "F1 Score: 0.8610541688829204\n",
            "Precision: 0.8657898130238555\n",
            "Recall: 0.8680851063829788\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Accuracy: 0.7191489361702128\n",
            "F1 Score: 0.6492174040820036\n",
            "Precision: 0.7686904376179676\n",
            "Recall: 0.7191489361702128\n",
            "\n",
            "------------------------------------\n",
            "Processing file: processed.cleveland.csv\n",
            "Results for file: processed.cleveland.csv\n",
            "Model: Logistic Regression\n",
            "Accuracy: 0.6157024793388429\n",
            "F1 Score: 0.5160471393183166\n",
            "Precision: 0.4631804718071831\n",
            "Recall: 0.6157024793388429\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "\n",
            "Model: Naive Bayes\n",
            "Accuracy: 0.5950413223140496\n",
            "F1 Score: 0.5495783720556368\n",
            "Precision: 0.545689367401617\n",
            "Recall: 0.5950413223140496\n",
            "\n",
            "Model: Neural Network\n",
            "Accuracy: 0.9958677685950413\n",
            "F1 Score: 0.9958510853946654\n",
            "Precision: 0.9958981526494896\n",
            "Recall: 0.9958677685950413\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Accuracy: 0.5991735537190083\n",
            "F1 Score: 0.501713745322972\n",
            "Precision: 0.4429741497748938\n",
            "Recall: 0.5991735537190083\n",
            "\n",
            "------------------------------------\n",
            "Processing file: processed.switzerland.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for file: processed.switzerland.csv\n",
            "Model: Logistic Regression\n",
            "Accuracy: 0.4897959183673469\n",
            "F1 Score: 0.4253328991170936\n",
            "Precision: 0.410760667903525\n",
            "Recall: 0.4897959183673469\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "\n",
            "Model: Naive Bayes\n",
            "Accuracy: 0.19387755102040816\n",
            "F1 Score: 0.2223612109269649\n",
            "Precision: 0.36411860029371557\n",
            "Recall: 0.19387755102040816\n",
            "\n",
            "Model: Neural Network\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Accuracy: 0.8775510204081632\n",
            "F1 Score: 0.8761904761904763\n",
            "Precision: 0.8819241982507288\n",
            "Recall: 0.8775510204081632\n",
            "\n",
            "------------------------------------\n",
            "Processing file: processed.va.csv\n",
            "Results for file: processed.va.csv\n",
            "Model: Logistic Regression\n",
            "Accuracy: 0.425\n",
            "F1 Score: 0.3880541069100391\n",
            "Precision: 0.41388526162971734\n",
            "Recall: 0.425\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "\n",
            "Model: Naive Bayes\n",
            "Accuracy: 0.425\n",
            "F1 Score: 0.4180319281355338\n",
            "Precision: 0.424505501499036\n",
            "Recall: 0.425\n",
            "\n",
            "Model: Neural Network\n",
            "Accuracy: 0.95\n",
            "F1 Score: 0.9494414348136259\n",
            "Precision: 0.9514583333333333\n",
            "Recall: 0.95\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Accuracy: 0.40625\n",
            "F1 Score: 0.3451591760299626\n",
            "Precision: 0.3207671404682274\n",
            "Recall: 0.40625\n",
            "\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.exceptions import ConvergenceWarning, UndefinedMetricWarning\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
        "\n",
        "# Directory containing multiple CSV files\n",
        "input_directory = \"/content/combined data\"\n",
        "\n",
        "# List all CSV files in the directory\n",
        "csv_files = [file for file in os.listdir(input_directory) if file.endswith('.csv')]\n",
        "\n",
        "for file in csv_files:\n",
        "    print(f\"Processing file: {file}\")\n",
        "\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(os.path.join(input_directory, file), header=None, names=['age', 'sex', 'cp', 'trestbps', 'chol', 'FBS', 'restecg', 'thalach', 'exang', 'Old peak', 'slope', 'ca', 'thal', 'num'])\n",
        "\n",
        "    # Replace '?' with NaN\n",
        "    df.replace('?', np.nan, inplace=True)\n",
        "\n",
        "    # Convert columns to numeric\n",
        "    df = df.apply(pd.to_numeric)\n",
        "\n",
        "    # Impute missing values with mean\n",
        "    df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "    # Define feature columns and target column\n",
        "    feature_columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'FBS', 'restecg', 'thalach', 'exang', 'Old peak', 'slope', 'ca', 'thal']\n",
        "    target_column = 'num'\n",
        "\n",
        "    # Separate features and target\n",
        "    X = df[feature_columns]\n",
        "    y = df[target_column]\n",
        "\n",
        "    # Scale the features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Split the scaled dataset into training and testing sets (80% training, 20% testing)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define models and parameter grids for hyperparameter tuning\n",
        "    models = {\n",
        "        \"Logistic Regression\": (LogisticRegression(max_iter=2000), {'model__C': [0.1, 1, 10]}),\n",
        "        \"Decision Tree\": (DecisionTreeClassifier(), {'model__max_depth': [None, 10, 20, 30]}),\n",
        "        \"Random Forest\": (RandomForestClassifier(), {'model__n_estimators': [50, 100, 200], 'model__max_depth': [None, 10, 20]}),  # Added max_depth hyperparameter\n",
        "        \"Naive Bayes\": (GaussianNB(), {}),\n",
        "        \"Neural Network\": (MLPClassifier(max_iter=1000), {'model__hidden_layer_sizes': [(100,), (50, 50), (20, 20, 20)]}),\n",
        "        \"Support Vector Machine\": (SVC(), {'model__C': [0.1, 1, 10], 'model__kernel': ['linear', 'rbf']})\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for model_name, (model, param_grid) in models.items():\n",
        "        pipeline = Pipeline([\n",
        "            ('feature_selection', RFE(estimator=DecisionTreeClassifier())),\n",
        "            ('model', model)\n",
        "        ])\n",
        "\n",
        "        # Perform grid search with cross-validation\n",
        "        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        # Best model from grid search\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # Make predictions on training set\n",
        "        y_train_pred = best_model.predict(X_train)\n",
        "\n",
        "        # Calculate evaluation metrics\n",
        "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "        train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
        "        train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
        "        train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "        results[model_name] = {\n",
        "            \"Accuracy\": train_accuracy,\n",
        "            \"F1 Score\": train_f1,\n",
        "            \"Precision\": train_precision,\n",
        "            \"Recall\": train_recall\n",
        "        }\n",
        "\n",
        "    # Display results for each file\n",
        "    print(f\"Results for file: {file}\")\n",
        "    for model_name, metrics in results.items():\n",
        "        print(f\"Model: {model_name}\")\n",
        "        for metric_name, value in metrics.items():\n",
        "            print(f\"{metric_name}: {value}\")\n",
        "        print()\n",
        "    print(\"------------------------------------\")\n"
      ]
    }
  ]
}